{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEbjxXTLL44D"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCWPmF5DL8_5"
      },
      "source": [
        "Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAY0-sMo9tAR",
        "outputId": "23ad9d63-83f2-4373-c893-5221975f6cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrtWHnYbMBj2"
      },
      "source": [
        "Set up mount symlink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "r5kJBJ60-10F"
      },
      "outputs": [],
      "source": [
        "# DRIVE_PATH = '/content/gdrive/My\\ Drive/PointNet\n",
        "DRIVE_PATH = '/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/PointNet'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZNpfeuJMFQg"
      },
      "source": [
        "## Import and others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "qVwSTMaw_jzB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXPMM9KtDwPj",
        "outputId": "daf9c20a-53d0-455c-9511-4c092d058f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dg_Ok4y5qZr",
        "outputId": "6f9926e7-e95e-4573-e9c4-ce793fca053e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM4FYhadbfGG"
      },
      "source": [
        "## Download data\n",
        "The url may change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msAfpLclcuUv",
        "outputId": "b236b4d3-6133-4953-fcdb-116bd8df88d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282\n",
            "Cloning into 'PointCloudAlchemist'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\n",
            "Unpacking objects: 100% (23/23), 232.02 MiB | 8.05 MiB/s, done.\n",
            "Updating files: 100% (10/10), done.\n",
            "/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist\n"
          ]
        }
      ],
      "source": [
        "%cd $SYM_PATH\n",
        "\n",
        "# This may take a few minutes\n",
        "if not os.path.exists(\"PointCloudAlchemist\"):\n",
        "    !git clone https://github.com/Joohwan-Seo/CS282A_final_project.git PointCloudAlchemist\n",
        "else:\n",
        "    print(\"Already downloaded.\")\n",
        "\n",
        "%cd PointCloudAlchemist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmH16Hst2jZJ",
        "outputId": "b802646c-483b-4556-d855-a2b6e952ed0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "-BlYpOHsaXBi"
      },
      "outputs": [],
      "source": [
        "from utils import PointCloudData, Normalize, RotateXYZ, AddGaussianNoise, read_off\n",
        "from network_sol import PointNetClassification, PointNetSegmentation, GetModel, PointNetLoss\n",
        "from train_sol import TrainModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNRmobM2MPLD"
      },
      "source": [
        "## visualize image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuOX8jiulNus"
      },
      "outputs": [],
      "source": [
        "# v, f = read_off(DATA_PATH/\"sofa/train/sofa_0001.off\")\n",
        "# print(v[0])\n",
        "# print(f[0], type(f[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE-UgwH5IPzV"
      },
      "outputs": [],
      "source": [
        "# i,j,k = np.array(f).T\n",
        "# x,y,z = np.array(v).T\n",
        "# print(len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0bE6YrMfca"
      },
      "source": [
        "## Training\n",
        "### Transformer for training.\n",
        "1024 points per cloud as in the paper!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "T8hG6GT-MxTH"
      },
      "outputs": [],
      "source": [
        "pointnet_tf = transforms.Compose([Normalize(),\n",
        "                                  RotateXYZ(),\n",
        "                                  AddGaussianNoise(),\n",
        "                                  transforms.ToTensor()\n",
        "                                ])\n",
        "torch.manual_seed(340420)\n",
        "\n",
        "all_data = {'train': PointCloudData(data_split = \"train\", method = 'random', acc_type = 'valid' , transform = pointnet_tf),\n",
        "            'test' : PointCloudData(data_split = \"test\",  method = 'random', acc_type = 'valid' , transform = pointnet_tf)\n",
        "            } \n",
        "\n",
        "all_dataloader = {'train': DataLoader(dataset = all_data['train'], batch_size = 32, shuffle = True),\n",
        "                  'test' : DataLoader(dataset = all_data['test'] , batch_size = 64)\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SV6zhlDMnGp",
        "outputId": "6af90406-f41a-4268-dfe7-467205024cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of train data = 3991\n",
            "# of test data = 908\n",
            "# of classes: 10\n",
            "Sampled pointcloud shape: torch.Size([1024, 3])\n",
            "Class of the 3990-th train data = toilet\n"
          ]
        }
      ],
      "source": [
        "num_to_class = {i: cat for cat, i in all_data['train'].classes.items()}\n",
        "\n",
        "for t in ['train', 'test']:\n",
        "    print(f\"# of {t} data = {len(all_data[t])}\")\n",
        "\n",
        "print(f\"# of classes: {len(all_data['train'].classes)}\")\n",
        "\n",
        "any_idx = 3990\n",
        "assert any_idx < len(all_data['train'])\n",
        "\n",
        "print(f\"Sampled pointcloud shape: {all_data['train'][any_idx]['pointcloud'].size()}\")\n",
        "print(f\"Class of the {any_idx}-th train data = {num_to_class[all_data['train'][any_idx]['category']]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srzb-HI9M6xA"
      },
      "source": [
        "### Model\n",
        "Three classes (`Tnet`, `Transform`, and `PointNet`) are defined above (model.py).  \n",
        "We also need a loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKQTQcyLNHwR"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "You can find a pretrained model here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "pD6Wa8ui5l18"
      },
      "outputs": [],
      "source": [
        "# If you rerun this cell, you will lost all your work\n",
        "model_dict, output_dict = {}, {}\n",
        "for tnet in ['yes_t', 'no_t']:\n",
        "    model_dict[tnet], output_dict[tnet] = {}, {}\n",
        "    for task in ['Classification', 'Segmentation']:\n",
        "        model_dict[tnet][task], output_dict[tnet][task] = None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "bQ-ggXMfNbQ_",
        "outputId": "4b9b931b-2e6d-4fba-d581-5e98d5d070b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 1  / 30, Batch: 25  / 125 >> Train loss: 1.987. Forward-backward path (s) = 0.08. Epoch time (s) = 2.39\n",
            "Epoch: 1  / 30, Batch: 50  / 125 >> Train loss: 1.838. Forward-backward path (s) = 0.07. Epoch time (s) = 4.58\n",
            "Epoch: 1  / 30, Batch: 75  / 125 >> Train loss: 1.792. Forward-backward path (s) = 0.08. Epoch time (s) = 6.77\n",
            "Epoch: 1  / 30, Batch: 100 / 125 >> Train loss: 1.793. Forward-backward path (s) = 0.08. Epoch time (s) = 8.97\n",
            "Epoch: 1  / 30, Batch: 125 / 125 >> Train loss: 1.679. Forward-backward path (s) = 0.05. Epoch time (s) = 11.15\n",
            "Accuracy: 28%\n",
            "---------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-183-6ad0e53d5c2d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m output_dict[tnet][task] = TrainModel(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_dataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/train.py\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, train_loader, valid_loader, num_epochs, optimizer, scheduler, device, save)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/network.py\u001b[0m in \u001b[0;36mPointNetLoss\u001b[0;34m(x, category, mtx_in, mtx_feature, alpha)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0midmtx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0midmtx_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tnet = 'yes_t' \n",
        "task = 'Classification'\n",
        "\n",
        "# set model and check device\n",
        "model_dict[tnet][task], optimizer, scheduler = GetModel(tnet, task, DEVICE)\n",
        "print(next(model_dict[tnet][task].parameters()).device)\n",
        "\n",
        "# train\n",
        "output_dict[tnet][task] = TrainModel(\n",
        "    task         = task,\n",
        "    model        = model_dict[tnet][task],\n",
        "    train_loader = all_dataloader['train'], # training\n",
        "    valid_loader = all_dataloader['test'],  # validation (and test)\n",
        "    num_epochs   = 30,\n",
        "    optimizer    = optimizer,\n",
        "    scheduler    = scheduler,\n",
        "    device       = DEVICE,\n",
        "    save         = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "9zCtLM0LMi_W",
        "outputId": "56a43ba4-5521-4d3e-ccba-dd6bc6883eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 1  / 30, Batch: 25  / 125 >> Train loss: 1.429. Forward-backward path (s) = 0.02. Epoch time (s) = 0.95\n",
            "Epoch: 1  / 30, Batch: 50  / 125 >> Train loss: 1.587. Forward-backward path (s) = 0.02. Epoch time (s) = 1.84\n",
            "Epoch: 1  / 30, Batch: 75  / 125 >> Train loss: 1.22 . Forward-backward path (s) = 0.02. Epoch time (s) = 2.74\n",
            "Epoch: 1  / 30, Batch: 100 / 125 >> Train loss: 1.451. Forward-backward path (s) = 0.02. Epoch time (s) = 3.75\n",
            "Epoch: 1  / 30, Batch: 125 / 125 >> Train loss: 1.195. Forward-backward path (s) = 0.02. Epoch time (s) = 4.79\n",
            "Accuracy: 48%\n",
            "---------------\n",
            "Epoch: 2  / 30, Batch: 25  / 125 >> Train loss: 1.473. Forward-backward path (s) = 0.02. Epoch time (s) = 1.04\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-fed146cf47f3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m output_dict[tnet][task] = TrainModel(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_dataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/train.py\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, train_loader, valid_loader, num_epochs, optimizer, scheduler, device, save)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mhistory_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tnet = 'no_t' \n",
        "task = 'Classification'\n",
        "\n",
        "# set model and check device\n",
        "model_dict[tnet][task], optimizer, scheduler = GetModel(tnet, task, DEVICE)\n",
        "print(next(model_dict[tnet][task].parameters()).device)\n",
        "\n",
        "# train\n",
        "output_dict[tnet][task] = TrainModel(\n",
        "    task         = task,\n",
        "    model        = model_dict[tnet][task],\n",
        "    train_loader = all_dataloader['train'], # training\n",
        "    valid_loader = all_dataloader['test'],  # validation (and test)\n",
        "    num_epochs   = 30,\n",
        "    optimizer    = optimizer,\n",
        "    scheduler    = scheduler,\n",
        "    device       = DEVICE,\n",
        "    save         = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "U0A-auZVn_Lv"
      },
      "outputs": [],
      "source": [
        "all_data = {'train': PointCloudData(data_split = \"train\", method = 'random', task = 'Segmentation', acc_type = 'valid' , transform = pointnet_tf),\n",
        "            'test' : PointCloudData(data_split = \"test\",  method = 'random', task = 'Segmentation', acc_type = 'valid' , transform = pointnet_tf)\n",
        "            } \n",
        "all_dataloader = {'train': DataLoader(dataset = all_data['train'], batch_size = 32, shuffle = True),\n",
        "                  'test' : DataLoader(dataset = all_data['test'] , batch_size = 64)\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "3r_VGm8tWxSN",
        "outputId": "3f493ac9-8f09-42bf-8241-66a277e0a299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 1  / 30, Batch: 25  / 45 >> Train loss: 1.215. Forward-backward path (s) = 0.26. Epoch time (s) = 7.54\n",
            "Accuracy: 51%\n",
            "---------------\n",
            "Epoch: 2  / 30, Batch: 25  / 45 >> Train loss: 1.071. Forward-backward path (s) = 0.28. Epoch time (s) = 7.68\n",
            "Accuracy: 61%\n",
            "---------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-61495317ac14>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m output_dict[tnet][task] = TrainModel(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtask\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/train.py\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(task, model, train_loader, valid_loader, num_epochs, optimizer, scheduler, device, save)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/network.py\u001b[0m in \u001b[0;36mPointNetLoss\u001b[0;34m(x, category, mtx_in, mtx_feature, alpha)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0midmtx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0midmtx_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tnet = 'yes_t' \n",
        "task = 'Segmentation'\n",
        "\n",
        "# set model and check device\n",
        "model_dict[tnet][task], optimizer, scheduler = GetModel(tnet, task, DEVICE)\n",
        "print(next(model_dict[tnet][task].parameters()).device)\n",
        "\n",
        "# train\n",
        "output_dict[tnet][task] = TrainModel(\n",
        "    task         = task,\n",
        "    model        = model_dict[tnet][task],\n",
        "    train_loader = all_dataloader['train'], # training\n",
        "    valid_loader = all_dataloader['test'],  # validation (and test)\n",
        "    num_epochs   = 30,\n",
        "    optimizer    = optimizer,\n",
        "    scheduler    = scheduler,\n",
        "    device       = DEVICE,\n",
        "    save         = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "s-8hVOUyWxLo",
        "outputId": "46db1cdf-bfd6-4795-ff5c-7a7aff8a983e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 1  / 30, Batch: 25  / 45 >> Train loss: 1.309. Forward-backward path (s) = 0.17. Epoch time (s) = 4.94\n",
            "Accuracy: 46%\n",
            "---------------\n",
            "Epoch: 2  / 30, Batch: 25  / 45 >> Train loss: 1.045. Forward-backward path (s) = 0.17. Epoch time (s) = 4.76\n",
            "Accuracy: 38%\n",
            "---------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-7cb7628f44a5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m output_dict[tnet][task] = TrainModel(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtask\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/Berkeley/Coursework/2023Spring/CS282/Project-cs282/PointCloudAlchemist/train.py\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(task, model, train_loader, valid_loader, num_epochs, optimizer, scheduler, device, save)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mhistory_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tnet = 'no_t' \n",
        "task = 'Segmentation'\n",
        "\n",
        "# set model and check device\n",
        "model_dict[tnet][task], optimizer, scheduler = GetModel(tnet, task, DEVICE)\n",
        "print(next(model_dict[tnet][task].parameters()).device)\n",
        "\n",
        "# train\n",
        "output_dict[tnet][task] = TrainModel(\n",
        "    task         = task,\n",
        "    model        = model_dict[tnet][task],\n",
        "    train_loader = all_dataloader['train'], # training\n",
        "    valid_loader = all_dataloader['test'],  # validation (and test)\n",
        "    num_epochs   = 30,\n",
        "    optimizer    = optimizer,\n",
        "    scheduler    = scheduler,\n",
        "    device       = DEVICE,\n",
        "    save         = False\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
