{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "SEbjxXTLL44D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount your Google Drive"
      ],
      "metadata": {
        "id": "GCWPmF5DL8_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAY0-sMo9tAR",
        "outputId": "f9e7ce5b-90a2-4f93-87a6-3c0030343e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up mount symlink"
      ],
      "metadata": {
        "id": "ZrtWHnYbMBj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DRIVE_PATH = '/content/gdrive/My\\ Drive/PointNet\n",
        "DRIVE_PATH = '/content/gdrive/MyDrive/PointNet'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/PointNet'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ],
      "metadata": {
        "id": "r5kJBJ60-10F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and others"
      ],
      "metadata": {
        "id": "eZNpfeuJMFQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $SYM_PATH\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FfOhOd4g_Z03",
        "outputId": "efc7f64c-8eae-41fa-dde0-6bc65e340480"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PointNet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/PointNet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "metadata": {
        "id": "qVwSTMaw_jzB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "uXPMM9KtDwPj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## args.py (seems to be unnecessary)"
      ],
      "metadata": {
        "id": "vEnhpWIRML8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# import argparse"
      ],
      "metadata": {
        "id": "HVNWJqeFFCkp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def parse_args():\n",
        "#     parser = argparse.ArgumentParser(description='')\n",
        "\n",
        "#     #  experiment settings\n",
        "#     parser.add_argument('--root_dir', default='../ModelNet10/', type=str,\n",
        "#                             help='dataset directory')\n",
        "#     parser.add_argument('--batch_size', default=32, type=int,\n",
        "#                             help='training batch size')\n",
        "#     parser.add_argument('--lr', default=1e-3, type=float,\n",
        "#                             help='learning rate')\n",
        "#     parser.add_argument('--epochs', default=15, type=int,\n",
        "#                             help='number of training epochs')\n",
        "#     parser.add_argument('--save_model_path', default='./checkpoints/', type=str,\n",
        "#                             help='checkpoints dir')\n",
        "\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "    \n",
        "#     assert args.root_dir is not None\n",
        "    \n",
        "#     print(' '.join(sys.argv))\n",
        "#     print(args)\n",
        "\n",
        "#     return args"
      ],
      "metadata": {
        "id": "ULi7SC7VFFxk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils.py"
      ],
      "metadata": {
        "id": "cNRmobM2MPLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_off(file):\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "    return verts, faces"
      ],
      "metadata": {
        "id": "tPNNUXK6Elbk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "class PointSampler(object):\n",
        "    def __init__(self, output_size, method = 'farthest', verbose = False):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "        self.method = method #NOTE(JH) 'original', 'farthest', 'default'\n",
        "        self.verbose = verbose \n",
        "\n",
        "    def triangle_area(self, pt1, pt2, pt3):\n",
        "        side_a = np.linalg.norm(pt1 - pt2)\n",
        "        side_b = np.linalg.norm(pt2 - pt3)\n",
        "        side_c = np.linalg.norm(pt3 - pt1)\n",
        "        s = 0.5 * ( side_a + side_b + side_c)\n",
        "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "\n",
        "    def sample_fartehst_point(self, point):\n",
        "        N, D = point.shape\n",
        "        centroids = np.zeros((self.output_size,))\n",
        "        distance = np.ones((N,)) * 1e10\n",
        "        farthest = np.random.randint(0,N)\n",
        "        for i in range(self.output_size):\n",
        "          centroids[i] = farthest\n",
        "          centroid = point[farthest, 0:3]\n",
        "          dist = np.sum((point[:,0:3] - centroid)**2, -1)\n",
        "          mask = dist < distance\n",
        "          distance[mask] = dist[mask]\n",
        "          farthest = np.argmax(distance, -1)\n",
        "        point = point[centroids.astype(np.int32)]\n",
        "\n",
        "        return point\n",
        "\n",
        "    def __call__(self, mesh):\n",
        "        verts, faces = mesh\n",
        "        verts = np.array(verts)\n",
        "        sampled_points = np.zeros((self.output_size, 3))        \n",
        "\n",
        "        # EDIT by JH-starts\n",
        "        # areas = np.zeros((len(faces)))\n",
        "        tic = time.time()\n",
        "        if self.method == 'default':\n",
        "          # N = min(self.output_size, len(faces))\n",
        "          \n",
        "          # if N == len(faces):\n",
        "          #     pass\n",
        "          # else:\n",
        "          #     inds = np.random.choice(len(faces), N, replace=False)\n",
        "          #     faces = [faces[ind] for ind in inds]\n",
        "\n",
        "          areas = np.zeros((len(faces)))\n",
        "\n",
        "          for i in range(len(areas)):\n",
        "              areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
        "                                            verts[faces[i][1]],\n",
        "                                            verts[faces[i][2]]))\n",
        "              \n",
        "          sampled_faces = (random.choices(faces,\n",
        "                                        weights=areas,\n",
        "                                        cum_weights=None,\n",
        "                                        k=self.output_size))\n",
        "        \n",
        "\n",
        "          for i in range(len(sampled_faces)):\n",
        "              sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
        "                                                    verts[sampled_faces[i][1]],\n",
        "                                                    verts[sampled_faces[i][2]]))\n",
        "        \n",
        "        elif self.method == 'original':\n",
        "          \n",
        "          inds = np.random.choice(len(verts), self.output_size, replace = True)\n",
        "\n",
        "          for i in range(sampled_points.shape[0]):\n",
        "              sampled_points[i] = (verts[inds[i]])\n",
        "\n",
        "        elif self.method == 'farthest':\n",
        "          # N = min(len(verts), 2 * self.output_size)\n",
        "          # if N == len(verts):\n",
        "          #   pass\n",
        "          # else:\n",
        "          #   inds = np.random.choice(len(verts), N, replace = False)\n",
        "          #   verts = verts[inds,:]\n",
        "          sampled_points = self.sample_fartehst_point(verts)\n",
        "\n",
        "        if self.verbose:\n",
        "          print('Sampling method:', self.method, '// Sampling time:', time.time() - tic)\n",
        "\n",
        "        # EDIT by JH-ends\n",
        "\n",
        "        return sampled_points\n",
        "\n",
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud\n",
        "\n",
        "class RandRotation_z(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        theta = random.random() * 2. * math.pi\n",
        "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                               [ math.sin(theta),  math.cos(theta),    0],\n",
        "                               [0,                             0,      1]])\n",
        "        \n",
        "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "        return  rot_pointcloud\n",
        "    \n",
        "class RandomNoise(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "    \n",
        "        noisy_pointcloud = pointcloud + noise\n",
        "        return  noisy_pointcloud\n",
        "        \n",
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ],
      "metadata": {
        "id": "4eF7Lan0DRcT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset.py"
      ],
      "metadata": {
        "id": "QDRi2rYnMWNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                PointSampler(1024), # utils.PointSampler(1024),\n",
        "                                Normalize(), # utils.Normalize(),\n",
        "                                ToTensor() # utils.ToTensor()\n",
        "                              ])\n",
        "    \n",
        "def train_transforms():\n",
        "    return transforms.Compose([\n",
        "                      PointSampler(1024,'farthest',verbose = False),\n",
        "                      Normalize(),\n",
        "                      RandRotation_z(),\n",
        "                      RandomNoise(),\n",
        "                      ToTensor()\n",
        "                      ])"
      ],
      "metadata": {
        "id": "jgvv-ZVgETP6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
        "        self.root_dir = root_dir\n",
        "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        self.transforms = transform if not valid else default_transforms()\n",
        "        self.valid = valid\n",
        "        self.files = []\n",
        "        for category in self.classes.keys():\n",
        "            new_dir = root_dir/Path(category)/folder\n",
        "            for file in os.listdir(new_dir):\n",
        "                if file.endswith('.off'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        verts, faces = read_off(file) # utils.read_off(file)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms((verts, faces))\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        with open(pcd_path, 'r') as f:\n",
        "            pointcloud = self.__preproc__(f)\n",
        "        return {'pointcloud': pointcloud,\n",
        "                'category': self.classes[category]}"
      ],
      "metadata": {
        "id": "dIA96ystEPPk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNetClass.ipynb"
      ],
      "metadata": {
        "id": "DIX4shj0FRGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.spatial.distance\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "2lBxkEM5ETzJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed = 42"
      ],
      "metadata": {
        "id": "vhZmUL75FYIL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download the dataset directly to the Google Colab Runtime.\n",
        "# # It comprises 10 categories, 3,991 models for training and 908 for testing.\n",
        "\n",
        "if not os.path.exists(\"ModelNet10\"): # This may take a few minutes\n",
        "  !wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip \n",
        "  !unzip -q ModelNet10.zip;\n",
        "\n",
        "path = Path(\"ModelNet10\")"
      ],
      "metadata": {
        "id": "wdkXmRwsFcz7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = path\n",
        "folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)}\n",
        "\n",
        "print(classes)\n",
        "\n",
        "method = 'farthest' # default, original, farthest\n",
        "\n",
        "# if target == 'training':\n",
        "  # transforms = train_transforms()\n",
        "# elif target == 'testing':\n",
        "  # transforms = default_transforms()\n",
        "pt = PointSampler(1024, method, False)\n",
        "\n",
        "folder = \"train\" #train, test\n",
        "\n",
        "data = []\n",
        "k = 0\n",
        "tic = time.time()\n",
        "for category in classes.keys():\n",
        "    new_dir = root_dir/Path(category)/folder\n",
        "    for file in os.listdir(new_dir):\n",
        "        if file.endswith('.off'):\n",
        "            sample = {}\n",
        "            sample['pcd_path'] = new_dir/file\n",
        "            sample['category'] = category\n",
        "\n",
        "            with open(sample['pcd_path'], 'r') as f:\n",
        "              verts, faces = read_off(f)\n",
        "              mesh = (verts, faces)\n",
        "              sampled_points = pt(mesh)\n",
        "\n",
        "            sample['sampled_points'] = sampled_points\n",
        "            data.append(sample)\n",
        "\n",
        "            k += 1\n",
        "\n",
        "            # if k == 10:\n",
        "            #   break\n",
        "\n",
        "print('Total folder number:', k)\n",
        "print('Total time is :', time.time() - tic)\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "hs9ynjJ1ZivF",
        "outputId": "ca4eec65-c888-4118-febe-4cc15cf7fba4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-0a3a8a904901>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pcd_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m               \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m               \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0msampled_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3d956aa686c5>\u001b[0m in \u001b[0;36mread_off\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_verts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_vert\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_verts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_face\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3d956aa686c5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_verts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_vert\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_verts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_face\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3d956aa686c5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_verts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_vert\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_verts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_face\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "name = folder + \"_\" + method + \".pkl\"\n",
        "\n",
        "print(name)\n",
        "\n",
        "file = open(name, 'wb')\n",
        "\n",
        "pickle.dump(data, file)\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVqUg8bEcqPz",
        "outputId": "de576da8-7d5b-4980-960d-9e31c27c8214"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_farthest.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                Normalize(), # utils.Normalize(),\n",
        "                                ToTensor() # utils.ToTensor()\n",
        "                              ])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ])\n",
        "\n",
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, method = 'default', target = 'train', transform=default_transforms()):\n",
        "        self.target = target\n",
        "        self.method = method\n",
        "\n",
        "        name = target + \"_\" + method + \".pkl\"\n",
        "\n",
        "        dataset = open(name, 'rb')\n",
        "        self.files = pickle.load(dataset)\n",
        "        dataset.close()\n",
        "\n",
        "        self.classes = {'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n",
        "\n",
        "                \n",
        "        # self.root_dir = root_dir\n",
        "        # folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "        # self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        # self.transforms = transform if not valid else default_transforms()\n",
        "        # self.valid = valid\n",
        "        # self.files = []\n",
        "        # for category in self.classes.keys():\n",
        "        #     new_dir = root_dir/Path(category)/folder\n",
        "        #     for file in os.listdir(new_dir):\n",
        "        #         if file.endswith('.off'):\n",
        "        #             sample = {}\n",
        "        #             sample['pcd_path'] = new_dir/file\n",
        "        #             sample['category'] = category\n",
        "        #             self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    # def __preproc__(self, file):\n",
        "    #     verts, faces = read_off(file) # utils.read_off(file)\n",
        "    #     if self.transforms:\n",
        "    #         pointcloud = self.transforms((verts, faces))\n",
        "    #     return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        pointcloud = self.files[idx]['sampled_points']\n",
        "\n",
        "        return {'pointcloud': pointcloud,\n",
        "                'category': self.classes[category]}"
      ],
      "metadata": {
        "id": "94Mbp4_3d3mG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PointCloudData('default','train',train_transforms)\n",
        "dataloader = DataLoader(dataset = train_dataset, batch_size = 1024, shuffle = True)\n",
        "\n",
        "for i,data in enumerate(dataloader):\n",
        "  print(i, data.values()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "GpqmKxUT6YMM",
        "outputId": "943358a9-a3a0-44fc-9a94-5c5fa0a1698b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-ebbdffe16234>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4eg1ad756nZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}